{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client =qdrant_client.QdrantClient(path=\"qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_store = Qdrant(\n",
    "    client=client, collection_name=\"touristic_info\", \n",
    "    embeddings=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Title: \\n', metadata={'source': '/Users/josepsmachine/Documents/PROGRAMMING/TOURIST_MAP_GENERATOR/crawled_files/https___www.lonelyplanet.com_articles_best-time-to-visit-norway_b7b14b.json', 'seq_num': 1}),\n",
       " Document(page_content='Title: Getting to Norway | How to travel to Norway\\nFrom Ireland, there is much less choice, but there are regular flights to Oslo Gardermoen airport. For travellers arriving from North America, the main decision is whether to fly direct to Oslo – though the options are limited – or via another European city, probably London. Australians, New Zealanders and South Africans have to fly via another country – there are no nonstop, direct flights. Finally, getting to Norway from the rest of Scandinavia (Denmark, Sweden and Finland) is quick, easy and relatively inexpensive, whether you travel by plane, bus or train. Flights from the UK From the UK, there’s a good choice of direct, nonstop flights from London to Oslo as well as a scattering of flights there from the UK’s regional airports. Norway’s main international airport is Oslo Gardermoen, 45km north of the city, but several budget airlines use the deceptively named Oslo (Torp) airport, which is actually just outside Sandefjord, 110km from Oslo, and Oslo (Rygge) airport, 60km south of the city near the little town of Moss. There are also a handful of nonstop, direct flights from the UK to other Norwegian cities, including Stavanger, Ålesund, Bergen and Trondheim, but for the likes of Tromsø you’ll have to change planes. Scandinavian Airlines (SAS) and its subsidiary Widerøe has the largest number of routes. Prices vary enormously, but Norwegian Airlines often offers the least expensive tickets with a return from London Gatwick or Manchester to Oslo costing from as little as £140. Flying times are insignificant: Aberdeen to Stavanger takes just one hour, London to Oslo a little over two. Flights from Ireland Flying from Ireland to Norway, there’s not much choice, but Ryanair (w ryanair.com) has flights from Dublin to Oslo (Rygge) and Norwegian Airlines (wnorwegian.com) flies between Dublin and Oslo Gardermoen. As sample fares, Norwegian charges anywhere between €70 and €160 for the flight from Dublin to Oslo with a flying time of just over two hours. Flights from the US and Canada From the US, you can fly direct/nonstop to Oslo Gardermoen from New York City with United Airlines (wunited.com) but otherwise you’ll have to change at a hub airport with London being an obvious choice. Return fares from major cities in the US to London start at around US$800, but otherwise reckon on spending around US$1500–2000 return for a nonstop New York–Oslo return flight with Continental. There are no direct flights to Norway from the west coast, but plenty of carriers will get you to Oslo with one stop, for as little as US$1500 return. From Canada, the best deals are usually offered by Air Canada (waircanada.com), which flies nonstop to London Heathrow, with onward connections to Norway. From Toronto to Oslo, expect to pay around Can$2000 in high season and Can$1500 in low season, while typical fares from Vancouver are around Can$2200 in high season and, likewise, Can$1500 in low season. The flying time on a direct, nonstop flight from the east coast of North America to Norway is just over seven hours. Flights from Australia and New Zealand There are no direct/nonstop flights from Australia or New Zealand to Norway. Most itineraries will involve two changes, one in the Far East – Singapore, Bangkok or Kuala Lumpur – and then another in the gateway city of the airline you’re flying with – most commonly Copenhagen, Amsterdam or London. You can get tickets to Oslo from Sydney, Melbourne or Perth for Aus$1500–2500, NZ$2000–3000 from Auckland.\\n\\nFlights from South Africa There are no direct/nonstop flights from South Africa to Norway, but several airlines will get you to Oslo with one stop via a European hub city. For example, KLM (wklm.com) fly from Cape Town to Amsterdam with onward connections to Oslo for a return fare of between ZAR9500 and ZAR12,500. By train from the UK Eurostar (w eurostar.com) services running through the Channel Tunnel to Brussels put Norway within reasonable striking distance of the UK by train, but the whole journey from London to Oslo, which is usually routed via Brussels and Copenhagen, still takes about 22 hours and costs about £300 one-way (£350 return), though special deals and concessionary rates can reduce these fares considerably. Rail passes If you’re visiting Norway as part of a longer European trip, it may be worth considering a pan-European rail pass. There are lots to choose from and Rail Europe (wraileurope.com and wraileurope.co.uk), the umbrella company for all national and international passes, operates a comprehensive website detailing all the options with prices. Note in particular that some passes have to be bought before leaving home, others can only be bought in specific countries. Note also that Inter-Rail Pass (winterrailnet.com) and Eurail Pass (weurail.com) holders get discounts on some internal ferry and bus journeys within Norway. Driving from the UK To reach Norway by car or motorbike from the UK, the best bet is to use Eurotunnel’s (weurotunnel.com) shuttle train through the Channel Tunnel. Note that Eurotunnel only carries cars (including occupants) and motorbikes, not cyclists and foot passengers. From the Eurotunnel exit in Calais, it’s a somewhat epic journey of around 1400km or so to Oslo. By ferry from the UK There are currently no car ferries from the UK to Norway; the nearest you’ll get is Esbjerg in Denmark, about 900km (around 10hr) by road from Oslo, with DFDS Seaways (wdfdsseaways.co.uk) from Harwich. Tariffs vary enormously, depending on when you leave, how long you stay, what size your vehicle is and how many passengers are in it; on overnight sailings, there is also the cost of a cabin to consider. As a sample fare, a seven-day, peak season return fare for two adults in an ordinary car costs around £250. Reservations are strongly recommended. There are three or four Harwich-to-Esbjerg sailings every week and the journey time is about eighteen hours.\\n\\nBy train, bus and ferry from the rest of Scandinavia and Russia By train you can reach Oslo from both Stockholm (2–3 daily; 6hr) and Copenhagen (2 daily; 8hr). There are also regular services from Stockholm to Narvik (1–2 daily; 21hr), operated by the Swedish company SJ (t00 46 771 75 75 75, wsj.se). For online tickets, go to wraileurope.com. Several bus companies provide services into Norway from other parts of Scandinavia. These include Eurolines (weurolines.co.uk) buses from London to Oslo, which pass through several Danish and Swedish towns, notably Copenhagen, Malmö and Gothenburg; the Swedish company GoByBus (wgobybus.se), which has services to Oslo from Stockholm, Copenhagen, Malmö and Gothenburg among others; and Swebuss (wswebus.se), which operates an express bus from Stockholm to Oslo. In the far north, Eskelisen Lapin Linjat (weskelisen-lapinlinjat.com) runs a number of bus services from Finland to Norwegian destinations, including Tromsø, Kirkenes and Nordkapp. A number of car ferries shuttle across the Skagerrak from Denmark to Norway. As for border crossings, there is (usually) little formality at either the Norway–Sweden or Norway–Finland borders, but the northern border with Russia is a different story. Border patrols (on either side) won’t be overjoyed at the prospect of you nosing around. If you have a genuine wish to visit Russia from Norway, it’s best to sort out the paperwork – visas and so forth – before you leave home. Kirkenes is the main starting point for tours into Russia from Norway. Tours and organized holidays Tourism in Norway is a multi-million-dollar industry that has spawned a small army of tour operators. Some provide generic bus tours of parts of the country, but there are many more specialist companies too, featuring everything from skiing and walking through to whale-watching and cycling. Most of the better companies offer a choice of escorted and independent tours. Additional, domestic tour operators are detailed throughout the Guide. Tour and holiday operators Anglers’ World Holidays UK t01246 221 717, wanglers-world.co.uk. Sea- and river-fishing holidays in Norway. Brekke Tours & Travel US t1 800 437 5302, wbrekketours.com. A well-established company offering a host of sightseeing and cultural tours of Scandinavia in general and Norway in particular. Discover the World UK t01737 214 251, wdiscover-the-world.co.uk. Specialist adventure tours including whale-watching in Norway, wildlife in Spitsbergen and dog-sledging in Lapland. Independent, tailor-made tours too. Exodus UK t0845 508 4197, w exodus.co.uk. Large, activity-holiday specialist offering cross-country skiing and all sorts of other winter sports plus whale-watching, hiking and Spitsbergen excursions. Headwater UK t0845 564 7148, wheadwater.com. Limited but well-chosen selection of winter fun holidays in Geilo and Venabu, where punters choose anything from skiing to reindeer safaris. High & Wild UK t0845 004 7801, whighandwild.co.uk. Adventure holiday specialist through whose services you can join a Sámi reindeer migration. Hurtigruten Norway t00 47 81 00 30 30, whurtigruten.com. The Hurtigruten coastal voyage is Norway’s most celebrated sea cruise (see Hurtigruten sailing schedule). Inntravel UK t01653 617 001, w inntravel.co.uk. Outdoor holidays in Norway including skiing, walking, dog-sledging, fjord cruises, and whale- and reindeer-watching. North South Travel UK t01245 608 291, wnorthsouthtravel.co.uk. Friendly, competitive travel agency, offering discounted fares worldwide. Profits are used to support projects in the developing world, especially the promotion of sustainable tourism. Saddle Skedaddle UK t0191 265 1110, skedaddle.co.uk. Highly recommended company organizing a couple of cycling tours of Norway each year, usually one to the Lofoten islands and another round the western fjords. Scandinavian America World Tours US t1 800 545 2204, wscandinaviantravel.com. Scandinavian specialist offering an extensive programme of group and individual tours and cruises within Norway. Scand-America US t1 727 415 5088, wscandamerica.com. A wide variety of packages – everything from dog-sledging to garden tours – throughout Scandinavia. Florida based. Scantours US t1 800 223 7226 wscantours.com. Huge range of packages and tailor-made holidays to every Scandinavian nook and cranny.\\n\\nThe Rough Guide to Norway and related travel guides\\n\\nTravel advice for Norway', metadata={'source': '/Users/josepsmachine/Documents/PROGRAMMING/TOURIST_MAP_GENERATOR/crawled_files/https___www.roughguides.com_norway_getting-there__480064.json', 'seq_num': 1}),\n",
       " Document(page_content=\"Title: Request for proposal – Visitnorway Meetings\\nCountry:\\n\\n--None-- UNITED STATES CANADA MEXICO AFGHANISTAN ÅLAND ISLANDS ALBANIA ALGERIA AMERICAN SAMOA ANDORRA ANGOLA ANGUILLA ANTARCTICA ANTIGUA AND BARBUDA ARGENTINA ARMENIA ARUBA AUSTRALIA AUSTRIA AZERBAIJAN BAHAMAS BAHRAIN BANGLADESH BARBADOS BELARUS BELGIUM BELIZE BENIN BERMUDA BHUTAN BOLIVIA, PLURINATIONAL STATE OF BOSNIA AND HERZEGOVINA BOTSWANA BOUVET ISLAND BRAZIL BRITISH INDIAN OCEAN TERRITORY BRUNEI DARUSSALAM BULGARIA BURKINA FASO BURUNDI CAMBODIA CAMEROON CANARY ISLANDS CAPE VERDE CAYMAN ISLANDS CENTRAL AFRICAN REPUBLIC CHAD CHILE CHINA CHRISTMAS ISLAND COCOS (KEELING) ISLANDS COLOMBIA COMOROS CONGO CONGO, THE DEMOCRATIC REPUBLIC OF THE COOK ISLANDS COSTA RICA CÔTE D'IVOIRE CROATIA CUBA CURACAO CYPRUS CZECH REPUBLIC DENMARK DJIBOUTI DOMINICA DOMINICAN REPUBLIC ECUADOR EGYPT EL SALVADOR EQUATORIAL GUINEA ERITREA ESTONIA ETHIOPIA FALKLAND ISLANDS (MALVINAS) FAROE ISLANDS FIJI FINLAND FRANCE FRENCH GUIANA FRENCH POLYNESIA FRENCH SOUTHERN TERRITORIES GABON GAMBIA GEORGIA GERMANY GHANA GIBRALTAR GREECE GREENLAND GRENADA GUADELOUPE GUAM GUATEMALA GUERNSEY GUINEA GUINEA-BISSAU GUYANA HAITI HEARD ISLAND AND MCDONALD ISLANDS HOLY SEE (VATICAN CITY STATE) HONDURAS HONG KONG HUNGARY ICELAND INDIA INDONESIA IRAN, ISLAMIC REPUBLIC OF IRAQ IRELAND ISLE OF MAN ISRAEL ITALY JAMAICA JAPAN JERSEY JORDAN KAZAKHSTAN KENYA KIRIBATI KOREA, DEMOCRATIC PEOPLE'S REPUBLIC OF KOREA, REPUBLIC OF KOSRAE KUWAIT KYRGYZSTAN LAO PEOPLE'S DEMOCRATIC REPUBLIC LATVIA LEBANON LESOTHO LIBERIA LIBYAN ARAB JAMAHIRIYA LIECHTENSTEIN LITHUANIA LUXEMBOURG MACAO MACEDONIA, THE FORMER YUGOSLAV REPUBLIC OF MADAGASCAR MALAWI MALAYSIA MALDIVES MALI MALTA MARSHALL ISLANDS MARTINIQUE MAURITANIA MAURITIUS MAYOTTE MICRONESIA, FEDERATED STATES OF MOLDOVA, REPUBLIC OF MONACO MONGOLIA MONTENEGRO MONTSERRAT MOROCCO MOZAMBIQUE MYANMAR NAMIBIA NAURU NEPAL NETHERLANDS NETHERLANDS ANTILLES NEW CALEDONIA NEW ZEALAND NICARAGUA NIGER NIGERIA NIUE NORFOLK ISLAND NORTHERN MARIANA ISLANDS NORWAY OMAN PAKISTAN PALAU PALESTINIAN TERRITORY, OCCUPIED PANAMA PAPUA NEW GUINEA PARAGUAY PERU PHILIPPINES PITCAIRN POLAND PONAPE PORTUGAL PUERTO RICO QATAR RÉUNION ROMANIA RUSSIAN FEDERATION RWANDA SABA SAINT BARTHÉLEMY SAINT HELENA SAINT KITTS AND NEVIS SAINT LUCIA SAINT MARTIN SAINT PIERRE AND MIQUELON SAINT VINCENT AND THE GRENADINES SAIPAN SAMOA SAN MARINO SAO TOME AND PRINCIPE SAUDI ARABIA SCOTLAND SENEGAL SERBIA SEYCHELLES SIERRA LEONE SINGAPORE SLOVAKIA SLOVENIA SOLOMON ISLANDS SOMALIA SOUTH AFRICA SOUTH GEORGIA AND THE SOUTH SANDWICH ISLANDS SPAIN SRI LANKA ST. BARTHELEMY ST. CHRISTOPHER ST. CROIX ST. EUSTATIUS ST. JOHN ST. MAARTEN ST. MARTIN ST. THOMAS SUDAN SURINAME SVALBARD AND JAN MAYEN SWAZILAND SWEDEN SWITZERLAND SYRIAN ARAB REPUBLIC TAIWAN, PROVINCE OF CHINA TAJIKISTAN TANZANIA, UNITED REPUBLIC OF THAILAND TIMOR-LESTE TINIAN TOGO TOKELAU TONGA TORTOLA TRINIDAD AND TOBAGO TRUK TUNISIA TURKEY TURKMENISTAN TURKS AND CAICOS ISLANDS TUVALU UGANDA UKRAINE UNION ISLAND UNITED ARAB EMIRATES UNITED KINGDOM UNITED STATES MINOR OUTLYING ISLANDS URUGUAY UZBEKISTAN VANUATU VENEZUELA, BOLIVARIAN REPUBLIC OF VIET NAM VIRGIN ISLANDS, BRITISH VIRGIN ISLANDS, U.S. WALES WALLIS AND FUTUNA WESTERN SAHARA YAP YEMEN ZAIRE ZAMBIA ZIMBABWE\", metadata={'source': '/Users/josepsmachine/Documents/PROGRAMMING/TOURIST_MAP_GENERATOR/crawled_files/https___www.visitnorway.com_meetings_rfp__8f92d4.json', 'seq_num': 1}),\n",
       " Document(page_content='Title: These are Norway’s UNESCO sites\\nAn important function of UNESCO (United Nations Educational, Scientific and Cultural Organization) is the conservation of nature and constructions that are not only significant to human history but are considered irreplaceable as well.\\n\\nThe selection is based on ten criteria that range from innovation and historical importance to unique nature.\\n\\nThese World Heritage Sites are found all over the world. Right now, there are more than 1000, covering everything from iconic man-made constructions such as The Great Wall of China, the Sydney Opera House, and the pyramids of Egypt to gigantic national parks, historical settlements, and different cultural and natural landscapes.\\n\\nIn 1979, Bryggen in Bergen was listed as the first Norwegian World Heritage Sites. The Rjukan–Notodden Industrial Heritage Site was added to UNESCO’s list in 2015.\\n\\nHere are the nine natural and cultural wonders that have made it to the list so far.', metadata={'source': '/Users/josepsmachine/Documents/PROGRAMMING/TOURIST_MAP_GENERATOR/crawled_files/https___www.visitnorway.com_places-to-go_unesco-world-heritage-sites__d8a7d5.json', 'seq_num': 1})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "found_docs = qdrant.max_marginal_relevance_search(query)\n",
    "found_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:03<00:00, 33.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "DRIVE_FOLDER = \"crawled_files\"\n",
    "\n",
    "loader = DirectoryLoader(DRIVE_FOLDER, glob='**/*.json', show_progress=True, loader_cls=JSONLoader, loader_kwargs = {'jq_schema':'.content'})\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant = Qdrant.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    path=\"qdrant\",\n",
    "    collection_name=\"my_documents\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes podcast player?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"podcast player\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/llms/openai.py:801: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EchoPod'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(\n",
    "          model_name=\"gpt-3.5-turbo\", # default model\n",
    "          temperature=0.9) #temperature dictates how whacky the output should be\n",
    "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
    "llmchain.run(\"podcast player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wk = Wikipedia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepsmachine/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/josepsmachine/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Could not find [oslo]. Similar: ['Oslo', 'Oslo (disambiguation)', 'Oslo Airport, Gardermoen', 'Oslo Accords', '2011 Norway attacks', 'University of Oslo', 'Oslo Pretenders', 'Oslo.', 'Sentrum, Oslo', 'Oslo (film)']\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wk.search(\"oslo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got unknown tool pal-math",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tools\n\u001b[1;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[43mload_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpal-math\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools,\n\u001b[1;32m      9\u001b[0m                          llm,\n\u001b[1;32m     10\u001b[0m                          agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mZERO_SHOT_REACT_DESCRIPTION,\n\u001b[1;32m     11\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/agents/load_tools.py:462\u001b[0m, in \u001b[0;36mload_tools\u001b[0;34m(tool_names, llm, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         tools\u001b[39m.\u001b[39mappend(tool)\n\u001b[1;32m    461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unknown tool \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    463\u001b[0m \u001b[39mif\u001b[39;00m callbacks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m tool \u001b[39min\u001b[39;00m tools:\n",
      "\u001b[0;31mValueError\u001b[0m: Got unknown tool pal-math"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"pal-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('crawled_files/https:__www.visitnorway.com_maps_.html').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 7927, which is longer than the specified 1000\n",
      "Created a chunk of size 3050, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 1126, which is longer than the specified 1000\n",
      "Created a chunk of size 1860, which is longer than the specified 1000\n",
      "Created a chunk of size 1304, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1923, which is longer than the specified 1000\n",
      "Created a chunk of size 1209, which is longer than the specified 1000\n",
      "Created a chunk of size 1178, which is longer than the specified 1000\n",
      "Created a chunk of size 1439, which is longer than the specified 1000\n",
      "Created a chunk of size 2080, which is longer than the specified 1000\n",
      "Created a chunk of size 2276, which is longer than the specified 1000\n",
      "Created a chunk of size 6251, which is longer than the specified 1000\n",
      "Created a chunk of size 1512, which is longer than the specified 1000\n",
      "Created a chunk of size 6095, which is longer than the specified 1000\n",
      "Created a chunk of size 1452, which is longer than the specified 1000\n",
      "Created a chunk of size 96030, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1298, which is longer than the specified 1000\n",
      "Created a chunk of size 1145, which is longer than the specified 1000\n",
      "Created a chunk of size 3528, which is longer than the specified 1000\n",
      "Created a chunk of size 1370, which is longer than the specified 1000\n",
      "Created a chunk of size 1779, which is longer than the specified 1000\n",
      "Created a chunk of size 1698, which is longer than the specified 1000\n",
      "Created a chunk of size 1440, which is longer than the specified 1000\n",
      "Created a chunk of size 2497, which is longer than the specified 1000\n",
      "Created a chunk of size 1244, which is longer than the specified 1000\n",
      "Created a chunk of size 1427, which is longer than the specified 1000\n",
      "Created a chunk of size 1465, which is longer than the specified 1000\n",
      "Created a chunk of size 1863, which is longer than the specified 1000\n",
      "Created a chunk of size 1097, which is longer than the specified 1000\n",
      "Created a chunk of size 1834, which is longer than the specified 1000\n",
      "Created a chunk of size 1273, which is longer than the specified 1000\n",
      "Created a chunk of size 1383, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:603\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    602\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 603\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    604\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    605\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    606\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    607\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    608\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    609\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    610\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    611\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    612\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    613\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    614\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:567\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \n\u001b[1;32m    541\u001b[0m \u001b[39mIf a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m    Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[1;32m    559\u001b[0m     collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[1;32m    560\u001b[0m     embedding_function\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    566\u001b[0m )\n\u001b[0;32m--> 567\u001b[0m chroma_collection\u001b[39m.\u001b[39;49madd_texts(texts\u001b[39m=\u001b[39;49mtexts, metadatas\u001b[39m=\u001b[39;49mmetadatas, ids\u001b[39m=\u001b[39;49mids)\n\u001b[1;32m    568\u001b[0m \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:187\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[1;32m    189\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/langchain/embeddings/huggingface.py:77\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m), texts))\n\u001b[0;32m---> 77\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mencode(texts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_kwargs)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[39m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(features)\n\u001b[1;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m output_value \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m features[\u001b[39m'\u001b[39m\u001b[39mtoken_type_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauto_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrans_features, return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[39m=\u001b[39m output_states[\u001b[39m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[39m.\u001b[39mupdate({\u001b[39m'\u001b[39m\u001b[39mtoken_embeddings\u001b[39m\u001b[39m'\u001b[39m: output_tokens, \u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m: features[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]})\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:550\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    549\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids\u001b[39m=\u001b[39minput_ids, position_ids\u001b[39m=\u001b[39mposition_ids, inputs_embeds\u001b[39m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 550\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    551\u001b[0m     embedding_output,\n\u001b[1;32m    552\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    553\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    554\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    555\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    556\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    557\u001b[0m )\n\u001b[1;32m    558\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    559\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:341\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    339\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 341\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    342\u001b[0m     hidden_states,\n\u001b[1;32m    343\u001b[0m     attention_mask,\n\u001b[1;32m    344\u001b[0m     head_mask[i],\n\u001b[1;32m    345\u001b[0m     position_bias,\n\u001b[1;32m    346\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    347\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    349\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:300\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    293\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    299\u001b[0m ):\n\u001b[0;32m--> 300\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    301\u001b[0m         hidden_states,\n\u001b[1;32m    302\u001b[0m         attention_mask,\n\u001b[1;32m    303\u001b[0m         head_mask,\n\u001b[1;32m    304\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    305\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    306\u001b[0m     )\n\u001b[1;32m    307\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    308\u001b[0m     outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add self attentions if we output attention weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:241\u001b[0m, in \u001b[0;36mMPNetAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    233\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    234\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    240\u001b[0m ):\n\u001b[0;32m--> 241\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[1;32m    242\u001b[0m         hidden_states,\n\u001b[1;32m    243\u001b[0m         attention_mask,\n\u001b[1;32m    244\u001b[0m         head_mask,\n\u001b[1;32m    245\u001b[0m         position_bias,\n\u001b[1;32m    246\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(self_outputs[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m hidden_states)\n\u001b[1;32m    249\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/haystack_stuff/lib/python3.9/site-packages/transformers/models/mpnet/modeling_mpnet.py:177\u001b[0m, in \u001b[0;36mMPNetSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(v)\n\u001b[1;32m    176\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(q, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[1;32m    178\u001b[0m attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention_head_size)\n\u001b[1;32m    180\u001b[0m \u001b[39m# Apply relative position embedding (precomputed in MPNetEncoder) if provided.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('haystack_stuff')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d930c8f90cef31d5c3eafdb0997039099ff2e11e0c9956a78e415db9fc54a201"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
